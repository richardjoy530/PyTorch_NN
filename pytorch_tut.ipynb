{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "colab": {
      "name": "pytorch_tut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5CEcBk-M9Ej",
        "colab_type": "text"
      },
      "source": [
        "# **About**\n",
        "\n",
        "This is a simple demonstration of implementing Neural Network using PyTorch.\n",
        "\n",
        "Basically this network echoes the input text that is given.\n",
        "\n",
        "Goal : =>  `'this is a test' => [Neural Network] => 'this is a test' `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKvc5ciDpWCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rj0-YYFFq3K",
        "colab_type": "text"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "hB-upPBzpWC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData = '''Lorem Ipsum is simply dummy text of the printing and typesetting industry Lorem Ipsum has been the industrys\n",
        "  standard dummy text ever since the when an unknown printer took a galley of type and scrambled it to make\n",
        "  a type specimen book It has survived not only five centuries but also the leap into electronic typesetting remaining\n",
        "  essentially unchanged It was popularised in the with the release of Letraset sheets containing Lorem Ipsum passages\n",
        "  and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum Why do we use\n",
        "  it It is a long established fact that a reader will be distracted by the readable content of a page when looking at its\n",
        "  layout The point of using Lorem Ipsum is that it has a moreorless normal distribution of letters as opposed to using\n",
        "  Content here content here making it look like readable English Many desktop publishing packages and web page\n",
        "  editors now use Lorem Ipsum as their default model text and a search for lorem ipsum will uncover many web\n",
        "  sites still in their infancy Various versions have evolved over the years sometimes by accident sometimes\n",
        "  on purpose injected humour and the like Where does it come from Contrary to popular belief Lorem Ipsum is not\n",
        "  simply random text It has roots in a piece of classical Latin literature from BC making it over years old\n",
        "  Richard McClintock a Latin professor at Hampden Sydney College in Virginia looked up one of the more obscure\n",
        "  Latin words consectetur from a Lorem Ipsum passage and going through the cites of the word in classical\n",
        "  literature discovered the undoubtable source Lorem Ipsum comes from sections  and  of de\n",
        "  Finibus Bonorum et Malorum The Extremes of Good and Evil by Cicero written in BC This book is a\n",
        "  treatise on the theory of ethics very popular during the Renaissance The first line of Lorem Ipsum Lorem\n",
        "  ipsum dolor sit amet comes from a line in section The standard chunk of Lorem Ipsum used\n",
        "  since the is reproduced below for those interested Sections and from de Finibus\n",
        "  Bonorum et Malorum by Cicero are also reproduced in their exact original form accompanied by English\n",
        "  versions from the translation by H Rackham Our loss function is what calculates how far off our classifications are from reality\n",
        "  As humans we tend to think of things in terms of either right or wrong With a neural network and arguably humans too\n",
        "  our accuracy is actually some sort of scaling score For example you might be highly confident that something is the case\n",
        "  but you are wrong Compare this to a time when you really arent certain either way but maybe think something but are wrong \n",
        "  In these cases the degree to which youre wrong doesnt matter in terms of the choice necessarily but in terms of you learning it does\n",
        "  In terms of a machine learning by tweaking lots of little parameters to slowly get closer and closer to fitting it \n",
        "  definitely matters how wrong things are For this we use loss which is a measurement of how far off the neural network \n",
        "  is from the targeted output There are a few types of loss calculations A popular one is mean squared error but were\n",
        "  trying to use these scalar valued classes In general youre going to have two types of classes One will\n",
        "  just be a scalar value the other is whats called a onehot array vector'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LenX9hjzQJBa",
        "colab_type": "text"
      },
      "source": [
        "This paragraph is split into words and saved in `trainset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGsm4CGQHXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = trainData.split()\n",
        "testset = ['hello','bye','see you','later']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGnlSBpLF29a",
        "colab_type": "text"
      },
      "source": [
        "# **Data PreProcessing functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GeIeB_3pWC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charTobin = {\n",
        "            'a': [0,0,0,0,0],'b': [0,0,0,0,1],'c': [0,0,0,1,0],'d': [0,0,0,1,1],\n",
        "            'e': [0,0,1,0,0],'f': [0,0,1,0,1],'g': [0,0,1,1,0],'h': [0,0,1,1,1],\n",
        "            'i': [0,1,0,0,0],'j': [0,1,0,0,1],'k': [0,1,0,1,0],'l': [0,1,0,1,1],\n",
        "            'm': [0,1,1,0,0],'n': [0,1,1,0,1],'o': [0,1,1,1,0],'p': [0,1,1,1,1],\n",
        "            'q': [1,0,0,0,0],'r': [1,0,0,0,1],'s': [1,0,0,1,0],'t': [1,0,0,1,1],\n",
        "            'u': [1,0,1,0,0],'v': [1,0,1,0,1],'w': [1,0,1,1,0],'x': [1,0,1,1,1],\n",
        "            'y': [1,1,0,0,0],'z': [1,1,0,0,1],' ': [1,1,0,1,0],' ': [1,1,0,1,1],\n",
        "            ' ': [1,1,1,0,0],' ': [1,1,1,0,1],' ': [1,1,1,1,0],' ': [1,1,1,1,1],\n",
        "  }\n",
        "\n",
        "binToChar = {\n",
        "            str([0,0,0,0,0]):'a',str([0,0,0,0,1]):'b',str([0,0,0,1,0]):'c',str([0,0,0,1,1]):'d',\n",
        "            str([0,0,1,0,0]):'e',str([0,0,1,0,1]):'f',str([0,0,1,1,0]):'g',str([0,0,1,1,1]):'h',\n",
        "            str([0,1,0,0,0]):'i',str([0,1,0,0,1]):'j',str([0,1,0,1,0]):'k',str([0,1,0,1,1]):'l',\n",
        "            str([0,1,1,0,0]):'m',str([0,1,1,0,1]):'n',str([0,1,1,1,0]):'o',str([0,1,1,1,1]):'p',\n",
        "            str([1,0,0,0,0]):'q',str([1,0,0,0,1]):'r',str([1,0,0,1,0]):'s',str([1,0,0,1,1]):'t',\n",
        "            str([1,0,1,0,0]):'u',str([1,0,1,0,1]):'v',str([1,0,1,1,0]):'w',str([1,0,1,1,1]):'x',\n",
        "            str([1,1,0,0,0]):'y',str([1,1,0,0,1]):'z',str([1,1,0,1,0]):' ',str([1,1,0,1,1]):' ',\n",
        "            str([1,1,1,0,0]):' ',str([1,1,1,0,1]):' ',str([1,1,1,1,0]):' ',str([1,1,1,1,1]):' '\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szlH0AQTpWDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordToBin(word):\n",
        "    wordBin = []\n",
        "    for c in word.lower():\n",
        "        wordBin.extend(charTobin[c])\n",
        "    while len(wordBin) < 20*5:\n",
        "        wordBin.append(1)\n",
        "    return torch.tensor(wordBin[0:100],requires_grad=True,dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKQA9uhapWDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binToWord(bintensor):\n",
        "    binList = bintensor.tolist()\n",
        "    binWord = []\n",
        "    word = ''\n",
        "    for i in range(20):\n",
        "        for j in range(i*5,(i+1)*5):\n",
        "            binWord.append(int(binList[j]))\n",
        "        word= word + binToChar[str(binWord)]\n",
        "        binWord = []\n",
        "    return word.strip()               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH85AOf8pWDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binToWord(wordToBin('test'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3eWlNNyCKdR",
        "colab_type": "text"
      },
      "source": [
        "# **NN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVJ1kvVpWDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(100, 256)\n",
        "        self.fc2 = nn.Linear(256, 100)\n",
        "        self.fc4 = nn.Linear(100, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc4(x))\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1AmpVKQpWDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qRS3FRUCDkb",
        "colab_type": "text"
      },
      "source": [
        "# **Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "1qKnyTSLpWDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.L1Loss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "for epoch in range(1000):\n",
        "    for data in trainset:\n",
        "        net.zero_grad()\n",
        "        inputData = wordToBin(data)\n",
        "        output = net(inputData)\n",
        "        loss = loss_function(output.view((1,100)), wordToBin(data).view((1,100)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Loss ==> ', loss.item(),' Epoch ===> ', epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT6x3GpjCTDw",
        "colab_type": "text"
      },
      "source": [
        "# Test\n",
        "\n",
        "The aim is to get the output same as the input.\n",
        "\n",
        "input text is the string given to the ` wordToBin() `. This function converts the string into binary for passing it into the Neural Network.\n",
        "\n",
        "This network outputs sigmoid values, therefore it has to be converted into binary inorder to convert it to string. Convertion to binary is done by `sig()`, i dont know if there is a builtin function for that, so i made one. This binary is converted to string using the same charector map with `binToWord()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wnGT_2ypWDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sig(x):\n",
        "    if x>.5:\n",
        "        return 1\n",
        "    if x<=.5:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7xvXNSxvW8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputData = wordToBin('tst')\n",
        "output = net(inputData)\n",
        "binToWord(torch.tensor(list(map(sig,output))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zslh5RbLcxp4",
        "colab_type": "text"
      },
      "source": [
        "# RoughWork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tklfMvhvcwr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# charTobin = {\n",
        "#             'a': 1,'b': 2,'c': 3,'d': 4,\n",
        "#             'e': 5,'f': 6,'g': 7,'h': 8,\n",
        "#             'i': 9,'j': 10,'k': 11,'l': 12,\n",
        "#             'm': 13,'n': 14,'o': 15,'p': 16,\n",
        "#             'q': 17,'r': 18,'s': 19,'t': 20,\n",
        "#             'u': 21,'v': 22,'w': 23,'x': 24,\n",
        "#             'y': 25,'z': 26,' ': 0\n",
        "# }\n",
        "\n",
        "# binToChar = {\n",
        "#             str(1):'a',str(2):'b',str(3):'c',str(4):'d',\n",
        "#             str(5):'e',str(6):'f',str(7):'g',str(8):'h',\n",
        "#             str(9):'i',str(10):'j',str(11):'k',str(12):'l',\n",
        "#             str(13):'m',str(14):'n',str(15):'o',str(16):'p',\n",
        "#             str(17):'q',str(18):'r',str(19):'s',str(20):'t',\n",
        "#             str(21):'u',str(22):'v',str(23):'w',str(24):'x',\n",
        "#             str(25):'y',str(26):'z',str(0):' '\n",
        "# }"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}